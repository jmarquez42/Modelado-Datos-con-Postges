# The purpose.

It is used to create the star schema for the application called Sparkify. This model is created from the song and artist data set. And with the activity records we build the fact table.

## Data set.

Song data set: This set contains the musics and artists

Log data set: contains the events generated by the users.

## ETL pipeline

The project is developed by 5 files.

* sql_queries.py - Contains SQL statements for creating tables, dropping tables, inserting data, and selecting data.

* create_tables.py: Contains the process that will generate the structure in the database from the instructions configured in the sql_queries.py file

* etl.py: It is the process in charge of ingesting the data.

* etl.ipynb: It is the file that allows to build the process interactively.

* test.ipynb - This file contains test queries to validate ingestion performed with the etl.ipynb file

## Instructions to run:

1. Execute the following command to create the database structure.

` python create_tables.py; echo $?`

***If the program ends with 0 it was executed correctly.***

2. Execute the following command to perform the ingestion.

`python create_tables.py; echo $?`

***If the program ends with 0 it was executed correctly.***
