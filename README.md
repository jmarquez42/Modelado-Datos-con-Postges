# Project data modeling with PostgreSQL.

### The purpose.

It is to create a star schema for the application called Sparkify. This model is created from the data set of the songs. And with the user activity records we build the fact table.

### Data set.

***Song datasets***: This set contains the musics and artists. A sample of this files is:
```
{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}
```

***Log datasets***: contains the events generated by the users. A sample of a single row of each files is:
```
{"artist":"Sydney Youngblood","auth":"Logged In","firstName":"Jacob","gender":"M","itemInSession":53,"lastName":"Klein","length":238.07955,"level":"paid","location":"Tampa-St. Petersburg-Clearwater, FL","method":"PUT","page":"NextSong","registration":1540558108796.0,"sessionId":954,"song":"Ain't No Sunshine","status":200,"ts":1543449657796,"userAgent":"\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.78.2 (KHTML, like Gecko) Version\/7.0.6 Safari\/537.78.2\"","userId":"73"}
```

### ETL pipeline

The project is developed by 5 files.

* ***sql_queries.py***: Contains SQL statements for creating tables, dropping tables, inserting data, and selecting data.

* ***create_tables.py***: Contains the process that will generate the structure in the database from the instructions configured in the sql_queries.py file

* ***etl.py***: It is the process in charge of ingesting the data.

* ***etl.ipynb***: It is the file that allows to build the process interactively.

* ***test.ipynb***: This file contains test queries to validate ingestion performed with the etl.ipynb file

### Prerequisites
* Python    3.6.3
* Psycopg2  2.7.4
* Pandas    0.23.3

### Installing.

1. Execute the following command to create the database structure.

> ` pytho.n create_tables.py; echo $?`

2. Execute the following command to perform the ingestion.

> `python etl.py; echo $?`

***If the program ends with 0 it was executed correctly.***

## Running the tests

To validate the ingest, you can run the queries in the test.ipynb file.

## Authors

* **Jose Marquez** - [Github](https://github.com/jmarquez42)

